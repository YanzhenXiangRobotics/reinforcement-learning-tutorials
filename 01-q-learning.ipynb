{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pleasant-witch",
   "metadata": {},
   "source": [
    "# Q-Learning in Reinforcement Learning\n",
    "\n",
    "Q-Learning is most primitive, but big part of algorithms to learn reinforcement learning.\n",
    "\n",
    "In order to understand how it works, first let's consider the expected rewards as follows.\n",
    "\n",
    "$$ R = \\sum_{t=0}^{\\infty} {\\gamma^t r_t} $$\n",
    "\n",
    "where $r_t$ is a reward value obtained at $t$ and $\\gamma$ is discount.\n",
    "\n",
    "For instance, when you try to grab an object, you will do the following 3 actions :\n",
    "\n",
    "- action #1 : Stretch your arm ($t=0$)<br>\n",
    "  Getting reward 0.\n",
    "- action #2 : Open your hand ($t=1$)<br>\n",
    "  Getting reward 0.\n",
    "- action #3 : Grab an object ($t=2$)<br>\n",
    "  Getting reward 10.\n",
    "\n",
    "In this case, you will get a reward value 10 on action #3 ($t=2$), however the action #1 ($t=0$) is obviously contributing to the final rewards. Hence, we consider that the action #1 will have the following expected cumulative reward.<br>\n",
    "Here we assume $\\gamma$ is 0.99.\n",
    "\n",
    "$$ R_{t=0} = 0 + 0.99 \\times 0 + 0.99^2 \\times 10 = 9.801 $$\n",
    "\n",
    "Same as above, $R_{t=1} = 9.9, R_{t=2} = 10$.\n",
    "\n",
    "Q-value is based on this idea of expected cumulative reward. Depending on each state (observation), the each action will have the corresponding expected reward.<br>\n",
    "In above example, if you see an object in front of you (i.e, the **state** of \"you see an object\"), the **action** \"stretching your arm\" will have high value of expected reward. However, if you cannot see an object anywhere, the action \"stretching your arm\" will have low value of expected reward.\n",
    "\n",
    "Q-value of each corresponding state and action is denoted as $Q(s, a)$. Suppose both action and state has 1 dimension of discrete values, $Q(s, a)$ will be written as a table (called Q-Table) as follows.\n",
    "\n",
    "![Q-Table](assets/q-table.png?raw=true)\n",
    "\n",
    "In practice, both action space and observation space may have more than 1 dimension. For instance, in CartPole example (below example), the returned state (observation) has 4 elements of float values, i.e, 4 dimensions. (See [readme.md](https://github.com/tsmatz/reinforcement-learning-tutorials/) for CartPole.) Then Q-Table will be the combination of 1 dimenstion (action space) and 4 dimenstion (observation space).\n",
    "\n",
    "In Q-Learning, we optimize this table by the following iterative updates ($t=0,1,2,\\ldots$).<br>\n",
    "In the following equation, $ Q_t(s_t,a_t) $ is current Q-value and $ Q_{t+1}(s_t,a_t) $ is the updated Q-value.\n",
    "\n",
    "$$ Q_{t+1}(s_t,a_t) = Q_t(s_t,a_t) + \\alpha \\left( r_t + \\gamma \\max_a{Q_t(s_{t+1},a)} - Q_t(s_t,a_t) \\right) $$\n",
    "\n",
    "where $\\alpha$ is learning rate.\n",
    "\n",
    "This equation means that :\n",
    "\n",
    "- Suppose, you executed an action $a_t$ on state $s_t$, and as a result, you got reward $r_t$ and the state has changed to $s_{t+1}$.\n",
    "- The optimal next action will satisfy $a_{t+1}=\\max_{a}{Q(s_{t+1},a)}$.<br>\n",
    "  By taking this optimal action, you will then get the expected reward : $r_t + \\gamma \\max_{a}{Q(s_{t+1},a)}$.\n",
    "- Compare this optimal q-value with current q-value $Q(s_t,a_t)$ in q-table. Then update this current value $Q(s_t,a_t)$ by learning rate $\\alpha$.<br>\n",
    "  This will result into above equation.\n",
    "\n",
    "Now let's build this Python example with CartPole environment. (See [readme.md](https://github.com/tsmatz/reinforcement-learning-tutorials/) about CartPole.)\n",
    "\n",
    "*(back to [index](https://github.com/tsmatz/reinforcement-learning-tutorials/))*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-minute",
   "metadata": {},
   "source": [
    "First, please install the required packages and import these modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy gym matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "creative-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-perspective",
   "metadata": {},
   "source": [
    "CartPole has 4 elements of continuos (float) observation space. In order for applying primitive Q-Learning, we should convert continuous state to discrete state (i.e, discretize).<br>\n",
    "In this example, we will convert Tuple(Box, Box, Box, Box) into Tuple(Discrete(20), Discrete(20), Discrete(20), Discrete(20)) - which converts float value to the value of index for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honey-house",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.32000017 -3.84000015 -3.36000013 -2.88000011 -2.4000001  -1.92000008\n",
      " -1.44000006 -0.96000004 -0.48000002  0.          0.48000002  0.96000004\n",
      "  1.44000006  1.92000008  2.4000001   2.88000011  3.36000013  3.84000015\n",
      "  4.32000017]\n",
      "[-3.6 -3.2 -2.8 -2.4 -2.  -1.6 -1.2 -0.8 -0.4  0.   0.4  0.8  1.2  1.6\n",
      "  2.   2.4  2.8  3.2  3.6]\n",
      "[-0.37699113 -0.33510323 -0.29321532 -0.25132742 -0.20943952 -0.16755161\n",
      " -0.12566371 -0.08377581 -0.0418879   0.          0.0418879   0.08377581\n",
      "  0.12566371  0.16755161  0.20943952  0.25132742  0.29321532  0.33510323\n",
      "  0.37699113]\n",
      "[-3.6 -3.2 -2.8 -2.4 -2.  -1.6 -1.2 -0.8 -0.4  0.   0.4  0.8  1.2  1.6\n",
      "  2.   2.4  2.8  3.2  3.6]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "new_observation_shape = (20, 20, 20, 20)\n",
    "\n",
    "bins = []\n",
    "for i in range(4):\n",
    "    item = np.linspace(\n",
    "        env.observation_space.low[i] if (i == 0) or (i == 2) else -4,\n",
    "        env.observation_space.high[i] if (i == 0) or (i == 2) else 4,\n",
    "        num=new_observation_shape[i],\n",
    "        endpoint=False)\n",
    "    item = np.delete(item, 0)\n",
    "    bins.append(item)\n",
    "    print(bins[i])\n",
    "\n",
    "# define function to convert to discrete state\n",
    "def get_discrete_state(s):\n",
    "    new_s = []\n",
    "    for i in range(4):\n",
    "        new_s.append(np.digitize(s[i], bins[i]))\n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-cincinnati",
   "metadata": {},
   "source": [
    "Now we generate Q-Table $Q(s,a)$ and initialize all values by 0. (Here it's 5 dimensional table.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "needed-communications",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 20, 20, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table = np.zeros(new_observation_shape + (env.action_space.n,))\n",
    "q_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-sacrifice",
   "metadata": {},
   "source": [
    "Now, update Q-Table with above Q-Learning algorithm.\n",
    "\n",
    "However, in the beginning, Q-Table was initialized all by zeros (not optimized at all) and will always pick up wrong actions. Therefore, the action is randomly picked up to explore in the first stage, and when it grows to learn, it then picks up the optimal actions with Q-Table gradually using the following coefficient parameter $\\epsilon$ to control. (This exploration algorithm is called **Epsilon-Greedy**.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fitted-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run episode5999 with rewards 200.0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.99\n",
    "alpha = 0.1\n",
    "epsilon = 1\n",
    "epsilon_decay = epsilon / 4000\n",
    "\n",
    "# pick up action from q-table with greedy exploration\n",
    "def pick_sample(s, episode_num):\n",
    "    # get optimal action,\n",
    "    # but with greedy exploration (to prevent picking up same values in the first stage)\n",
    "    if np.random.random() > epsilon:\n",
    "        a = np.argmax(q_table[tuple(s)])\n",
    "    else:\n",
    "        a = np.random.randint(0, env.action_space.n)\n",
    "    return a\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "reward_records = []\n",
    "for i in range(6000):\n",
    "    # Run episode till done\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    s = env.reset()\n",
    "    s_dis = get_discrete_state(s)\n",
    "    while not done:\n",
    "        a = pick_sample(s_dis, i)\n",
    "        s, r, done, _ = env.step(a)\n",
    "        s_dis_next = get_discrete_state(s)\n",
    "\n",
    "        # Update Q-Table\n",
    "        maxQ = np.max(q_table[tuple(s_dis_next)])\n",
    "        q_table[tuple(s_dis)][a] += alpha * (r + gamma * maxQ - q_table[tuple(s_dis)][a])\n",
    "\n",
    "        s_dis = s_dis_next\n",
    "        total_reward += r\n",
    "\n",
    "    # Update epsilon for each episode\n",
    "    if epsilon - epsilon_decay >= 0:\n",
    "        epsilon -= epsilon_decay\n",
    "    \n",
    "    # Record total rewards in episode (max 200)\n",
    "    print(\"Run episode{} with rewards {}\".format(i, total_reward), end=\"\\r\")\n",
    "    reward_records.append(total_reward)\n",
    "\n",
    "print(\"\\nDone\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "final-neighbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8235d492e8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(reward_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-butterfly",
   "metadata": {},
   "source": [
    "As you can see above, this method won't work in large continuous and stochastic spaces (e.g, continuos action space), since this method will need so many discrete mesh for solving problems.<br>\n",
    "In the next tutorial, we'll learn the idea of policy gradient methods, which will take effects in such a case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-champagne",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
